"""
bot/transcription.py - Integra√ß√£o com API Whisper (M√°xima Precis√£o).

Envia √°udio para a API Whisper da OpenAI e retorna a transcri√ß√£o
com detec√ß√£o autom√°tica de idioma.

Configura√ß√£o de M√ÅXIMA PRECIS√ÉO:
    - temperature=0: Zero criatividade, apenas o que foi dito
    - language=None: Detec√ß√£o autom√°tica (n√£o for√ßa idioma)
    - response_format='verbose_json': Retorna idioma + segmentos
    - Sem prompt: Evita vi√©s/indu√ß√£o na transcri√ß√£o

Detec√ß√£o multil√≠ngue:
    O Whisper detecta O IDIOMA PREDOMINANTE do √°udio.
    Para detec√ß√£o de m√∫ltiplos idiomas em um s√≥ √°udio,
    analisamos os segmentos individuais (cada segmento
    tem ~30s e pode ter idioma diferente detectado).

Custos:
    Whisper: $0.006 por minuto de √°udio
    Exemplo: 5 minutos de √°udio = $0.03

Uso:
    from bot.transcription import transcribe_audio

    result = await transcribe_audio("caminho/do/audio.mp3")
    print(result['text'])       # Texto transcrito
    print(result['language'])   # Idioma principal
"""

import asyncio
import logging
from dataclasses import dataclass, field

from openai import OpenAI, APIError, APITimeoutError

from bot.prompts import PROMPTS
from bot.utils import get_language_name, format_duration
from config.settings import settings

logger = logging.getLogger(__name__)

# Timeout para a API Whisper (segundos)
# √Åudios longos podem demorar ‚Äî 5 min √© um limite seguro
WHISPER_TIMEOUT = 300

# N√∫mero m√°ximo de tentativas em caso de erro
MAX_RETRIES = 3

# Tempo base de espera entre retries (dobra a cada tentativa)
BASE_RETRY_DELAY = 2.0


@dataclass
class TranscriptionResult:
    """
    Resultado de uma transcri√ß√£o de √°udio.

    Atributos:
        text: Texto transcrito completo.
        language: C√≥digo do idioma principal (ex: "pt", "en").
        language_name: Nome leg√≠vel do idioma (ex: "üáßüá∑ Portugu√™s").
        detected_languages: Lista de idiomas detectados (se multil√≠ngue).
        is_multilingual: True se mais de um idioma foi detectado.
        duration: Dura√ß√£o do √°udio em segundos.
    """

    text: str
    language: str
    language_name: str = ""
    detected_languages: list[str] = field(default_factory=list)
    is_multilingual: bool = False
    duration: float = 0.0

    def __post_init__(self):
        """Preenche language_name automaticamente."""
        if not self.language_name and self.language:
            self.language_name = get_language_name(self.language)


class TranscriptionError(Exception):
    """
    Exce√ß√£o para erros na transcri√ß√£o.

    Cont√©m mensagem user-friendly para enviar ao Telegram.
    """

    def __init__(self, user_message: str, technical_detail: str = ""):
        self.user_message = user_message
        self.technical_detail = technical_detail
        super().__init__(user_message)


def _detect_languages_from_segments(segments: list[dict]) -> list[str]:
    """
    Analisa segmentos para detectar m√∫ltiplos idiomas.

    O Whisper retorna segmentos de ~30s cada um. Cada segmento
    pode ter um idioma diferente detectado via heur√≠stica.

    Nota: Na pr√°tica, Whisper retorna apenas o idioma principal.
    Os segmentos n√£o cont√™m idioma individualmente na API atual.
    Para detec√ß√£o multil√≠ngue real, comparamos o idioma detectado
    com sinais no texto (caracteres especiais, padr√µes de palavras).

    Args:
        segments: Lista de segmentos do verbose_json.

    Retorna:
        Lista de c√≥digos de idiomas detectados.
    """
    # Whisper retorna idioma no n√≠vel do √°udio inteiro, n√£o por segmento.
    # Retornamos lista vazia ‚Äî o idioma principal vem da resposta top-level.
    return []


def _create_openai_client() -> OpenAI:
    """
    Cria e retorna um cliente OpenAI configurado.

    Usa a chave da API definida nas settings.
    Timeout configurado para √°udios longos.
    """
    return OpenAI(
        api_key=settings.OPENAI_API_KEY,
        timeout=WHISPER_TIMEOUT,
    )


async def transcribe_audio(file_path: str) -> TranscriptionResult:
    """
    Transcreve um arquivo de √°udio usando a API Whisper.

    Pipeline:
        1. Abre o arquivo de √°udio
        2. Envia para Whisper com configura√ß√£o de m√°xima precis√£o
        3. Extrai idioma detectado e texto
        4. Analisa segmentos para detec√ß√£o multil√≠ngue
        5. Retry autom√°tico com backoff exponencial em caso de erro

    Configura√ß√£o de precis√£o:
        - temperature=0: Sa√≠da determin√≠stica, sem "criatividade"
        - language=None: Whisper detecta o idioma automaticamente
        - verbose_json: Retorna metadados completos (idioma, dura√ß√£o, segments)

    Args:
        file_path: Caminho do arquivo de √°udio (preferencialmente MP3).

    Retorna:
        TranscriptionResult: Objeto com texto, idioma e metadados.

    Raises:
        TranscriptionError: Se todas as tentativas falharem.
    """
    client = _create_openai_client()
    last_error: Exception | None = None

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            logger.info(
                f"[WHISPER] Iniciando transcri√ß√£o (tentativa {attempt}/{MAX_RETRIES}): "
                f"{file_path}"
            )

            # Executa a chamada s√≠ncrona da OpenAI em thread separada
            # para n√£o bloquear o event loop do asyncio
            result = await asyncio.to_thread(
                _call_whisper_api, client, file_path
            )

            return result

        except APITimeoutError as e:
            last_error = e
            logger.warning(
                f"[WHISPER] Timeout na tentativa {attempt}/{MAX_RETRIES}: {e}"
            )

        except APIError as e:
            last_error = e
            logger.error(
                f"[WHISPER] Erro da API na tentativa {attempt}/{MAX_RETRIES}: "
                f"status={e.status_code}, message={e.message}"
            )

            # Erros 4xx (exceto 429) n√£o fazem sentido retry
            if e.status_code and 400 <= e.status_code < 500 and e.status_code != 429:
                break

        except Exception as e:
            last_error = e
            logger.error(
                f"[WHISPER] Erro inesperado na tentativa {attempt}/{MAX_RETRIES}: {e}"
            )

        # Backoff exponencial: 2s, 4s, 8s...
        if attempt < MAX_RETRIES:
            delay = BASE_RETRY_DELAY * (2 ** (attempt - 1))
            logger.info(f"[WHISPER] Aguardando {delay}s antes de retry...")
            await asyncio.sleep(delay)

    # Todas as tentativas falharam
    error_detail = str(last_error) if last_error else "Erro desconhecido"
    logger.error(f"[WHISPER] Todas as {MAX_RETRIES} tentativas falharam: {error_detail}")

    if isinstance(last_error, APITimeoutError):
        raise TranscriptionError(
            "‚è±Ô∏è O processamento excedeu o tempo limite (5 minutos).\n"
            "üí° Tente enviar um √°udio menor.",
            technical_detail=error_detail,
        )

    raise TranscriptionError(
        "‚ùå Erro ao transcrever o √°udio.\n"
        "üí° Tente novamente em alguns instantes.",
        technical_detail=error_detail,
    )


def _call_whisper_api(client: OpenAI, file_path: str) -> TranscriptionResult:
    """
    Chamada s√≠ncrona √† API Whisper (executada em thread separada).

    Esta fun√ß√£o √© s√≠ncrona porque o cliente OpenAI Python
    n√£o tem vers√£o async nativa para transcri√ß√£o. Usamos
    asyncio.to_thread() para n√£o bloquear o event loop.

    Args:
        client: Cliente OpenAI configurado.
        file_path: Caminho do arquivo de √°udio.

    Retorna:
        TranscriptionResult com texto e metadados.
    """
    with open(file_path, "rb") as audio_file:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="verbose_json",
            temperature=settings.WHISPER_TEMPERATURE,
            # language=None ‚Üí auto-detect (n√£o passamos o par√¢metro)
            # prompt=None ‚Üí sem indu√ß√£o (evita alucina√ß√µes)
        )

    # Extrai dados da resposta
    text = response.text.strip()
    language = getattr(response, "language", "unknown")
    duration = getattr(response, "duration", 0.0)
    segments = getattr(response, "segments", [])

    # Detecta m√∫ltiplos idiomas via segmentos
    segment_languages = _detect_languages_from_segments(segments)
    all_languages = [language] + [
        lang for lang in segment_languages if lang != language
    ]
    is_multilingual = len(set(all_languages)) > 1

    logger.info(
        f"[WHISPER] Transcri√ß√£o conclu√≠da: "
        f"idioma={language}, "
        f"dura√ß√£o={format_duration(duration)}, "
        f"caracteres={len(text)}, "
        f"multil√≠ngue={is_multilingual}"
    )

    return TranscriptionResult(
        text=text,
        language=language,
        detected_languages=list(dict.fromkeys(all_languages)),  # unique, order preserved
        is_multilingual=is_multilingual,
        duration=duration,
    )


async def post_process_transcription(text: str, format_type: str) -> str:
    """
    Processa a transcri√ß√£o com GPT-4o-mini para o formato desejado.

    Args:
        text: Texto original da transcri√ß√£o.
        format_type: 'summary', 'minutes' ou 'corrected'.

    Retorna:
        Texto processado no formato solicitado.
    """
    if format_type not in PROMPTS:
        return text  # Se n√£o houver prompt, retorna original (fallback)

    client = _create_openai_client()
    prompt = PROMPTS[format_type].replace("{transcription_text}", text)

    try:
        logger.info(f"[GPT] Processando formato '{format_type}' com gpt-4o-mini")
        
        # Chamada s√≠ncrona em thread separada
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Assistant de processamento de texto corporativo."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2, # Baixa criatividade para manter fidelidade
            max_tokens=1500
        )
        
        return response.choices[0].message.content.strip()

    except Exception as e:
        logger.error(f"[GPT] Erro no processamento: {e}")
        return f"‚ö†Ô∏è Erro ao gerar {format_type}. Segue transcri√ß√£o original:\n\n{text}"
